# ğŸ¤– Production-Grade GenAI Assistant with RAG

A scalable, production-ready AI support assistant powered by **Google Gemini 2.5 Flash** and **Retrieval-Augmented Generation (RAG)**. The system delivers grounded, context-aware responses using semantic search, conversation memory, and a modular backend architecture.

---

# ğŸš€ Live Demo

ğŸŒ **Deployed URL:** [https://production-grade-genai-assistant-with.onrender.com](https://production-grade-genai-assistant-with.onrender.com)

---

# âœ¨ Key Features

âœ… End-to-end RAG pipeline
âœ… Semantic search with cosine similarity
âœ… Conversation memory using SQLite
âœ… Grounded responses (antiâ€‘hallucination prompt)
âœ… Production deployment on Render
âœ… Modular backend architecture
âœ… Environmentâ€‘secure API key handling

---

# ğŸ—ï¸ System Architecture

```
User Query
   â†“
Express API
   â†“
Query Embedding (gemini-embedding-001)
   â†“
Similarity Search (Topâ€‘K)
   â†“
Context Retrieval
   â†“
Gemini 2.5 Flash
   â†“
Grounded Response
```

---

# ğŸ”„ RAG Workflow

## 1ï¸âƒ£ Document Ingestion

* Load documents from `docs.json`
* Chunk content (300 words + 50 overlap)
* Generate embeddings
* Store vectors in local vector store

## 2ï¸âƒ£ Query Processing

* Convert user query â†’ embedding
* Perform cosine similarity search
* Retrieve topâ€‘K relevant chunks
* Apply similarity threshold (0.7)

## 3ï¸âƒ£ Response Generation

* Inject retrieved context into prompt
* Include conversation history
* Generate grounded response
* Low temperature (0.2) to reduce hallucinations

---

# ğŸ“Š Embedding Strategy

| Parameter  | Value                |
| ---------- | -------------------- |
| Model      | gemini-embedding-001 |
| Dimensions | 3072                 |
| Chunk Size | 300 words            |
| Overlap    | 50 words             |
| Similarity | Cosine               |
| Threshold  | 0.7                  |
| Retrieval  | Topâ€‘3                |

---

# ğŸ›  Tech Stack

**Backend**

* Node.js
* Express.js

**LLM & AI**

* Gemini 2.5 Flash
* gemini-embedding-001

**Database**

* SQLite (session memory)

**Vector Store**

* JSON (inâ€‘memory)

**Frontend**

* Vanilla JavaScript
* HTML/CSS

**Deployment**

* Render

---

# ğŸ”Œ API Endpoints

## POST `/api/chat`

**Request**

```json
{
  "sessionId": "session_123",
  "message": "How can I reset my password?"
}
```

**Response**

```json
{
  "reply": "...grounded answer..."
}
```

---

## GET `/api/health`

Returns system status, model info, and vector store stats.

---

# âš™ï¸ Local Setup

## 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Shiva1msk/Production-Grade-GenAI-Assistant-with-RAG
cd Production-Grade-GenAI-Assistant-with-RAG
```

## 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

## 3ï¸âƒ£ Configure Environment

```bash
cp .env.example .env
```

Add your key:

```
GEMINI_API_KEY=your_key_here
PORT=3000
```

## 4ï¸âƒ£ Generate Vector Store

```bash
npm run ingest
```

## 5ï¸âƒ£ Start Server

```bash
npm start
```

Open:

ğŸ‘‰ [http://localhost:3000](http://localhost:3000)

---

# ğŸ”’ Security

* API keys stored in environment variables
* `.env` excluded via `.gitignore`
* Input validation on all endpoints
* No hardâ€‘coded secrets

---

# ğŸ“ˆ Current System Status

âœ… Backend: Operational
âœ… RAG Pipeline: Functional
âœ… Embeddings: Working
âœ… Gemini Chat: Working
âœ… Deployment: Live on Render

---

# ğŸš€ Production Roadmap

## ğŸ¥‡ High Priority

* [ ] Migrate to Pinecone / Qdrant
* [ ] Increase knowledge base size
* [ ] Add streaming responses
* [ ] Add source citations

## ğŸ¥ˆ Medium Priority

* [ ] Hybrid search (BM25 + vector)
* [ ] Authentication layer (JWT)
* [ ] Redis session store
* [ ] Improved chat UI

## ğŸ¥‰ Advanced Enhancements

* [ ] Multiâ€‘document upload
* [ ] Reranking model
* [ ] Observability & tracing
* [ ] Toolâ€‘calling agents

---

# ğŸ¯ Use Cases

* AI customer support bot
* Knowledge base assistant
* Internal company chatbot
* Documentation Q&A system
* Helpdesk automation

---

# â­ Contributing

Contributions, issues, and feature requests are welcome!

If you like this project, please â­ the repo.

---

# ğŸ‘¨â€ğŸ’» Author

**Shiva Kumar Maidam**
DevSecOps & Software Engineer

---

# ğŸ“œ License

This project is open-source and available under the MIT License.

---

> ğŸš€ Built to demonstrate production-grade RAG architecture with modern Gemini models.
